{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":19151,"sourceType":"datasetVersion","datasetId":14240},{"sourceId":3358601,"sourceType":"datasetVersion","datasetId":1624347},{"sourceId":10019735,"sourceType":"datasetVersion","datasetId":6169670}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Numeric data or ... ?\n\nIn this exercise, and throughout this chapter, you'll be working with bicycle ride sharing data in San Francisco called ride_sharing. It contains information on the start and end stations, the trip duration, and some user information for a bike sharing service.\n\nThe user_type column contains information on whether a user is taking a free ride and takes on the following values:\n\n1. for free riders.\n2. for pay per ride.\n3. for monthly subscribers.\n\nIn this instance, you will print the information of ride_sharing using .info() and see a firsthand example of how an incorrect data type can flaw your analysis of the dataset. The pandas package is imported as pd.\n\n\n* Print the information of ride_sharing.\n* Use .describe() to print the summary statistics of the user_type column from ride_sharing\n* Convert user_type into categorical by assigning it the 'category' data type and store it in the user_type_cat column.\n* Make sure you converted user_type_cat correctly by using an assert statement.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\n\nride_sharing = pd.read_csv(\"/kaggle/input/chicago-divvy-bicycle-sharing-data/data.csv\")\n\nride_sharing.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:03:25.832292Z","iopub.execute_input":"2024-12-30T15:03:25.832576Z","iopub.status.idle":"2024-12-30T15:03:55.985057Z","shell.execute_reply.started":"2024-12-30T15:03:25.832554Z","shell.execute_reply":"2024-12-30T15:03:55.984335Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   trip_id  year  month  week  day  hour    usertype  gender  \\\n0  2355134  2014      6    27    0    23  Subscriber    Male   \n1  2355133  2014      6    27    0    23  Subscriber    Male   \n2  2355130  2014      6    27    0    23  Subscriber    Male   \n3  2355129  2014      6    27    0    23  Subscriber  Female   \n4  2355128  2014      6    27    0    23  Subscriber  Female   \n\n             starttime             stoptime  ...  from_station_id  \\\n0  2014-06-30 23:57:00  2014-07-01 00:07:00  ...              131   \n1  2014-06-30 23:56:00  2014-07-01 00:00:00  ...              282   \n2  2014-06-30 23:33:00  2014-06-30 23:35:00  ...              327   \n3  2014-06-30 23:26:00  2014-07-01 00:24:00  ...              134   \n4  2014-06-30 23:16:00  2014-06-30 23:26:00  ...              320   \n\n             from_station_name latitude_start  longitude_start  \\\n0    Lincoln Ave & Belmont Ave      41.939365       -87.668385   \n1      Halsted St & Maxwell St      41.864580       -87.646930   \n2  Sheffield Ave & Webster Ave      41.921687       -87.653714   \n3     Peoria St & Jackson Blvd      41.877749       -87.649633   \n4     Loomis St & Lexington St      41.872187       -87.661501   \n\n  dpcapacity_start  to_station_id           to_station_name  latitude_end  \\\n0             15.0            303   Broadway & Cornelia Ave     41.945512   \n1             15.0             22        May St & Taylor St     41.869482   \n2             19.0            225  Halsted St & Dickens Ave     41.919936   \n3             19.0            194      State St & Wacker Dr     41.887155   \n4             15.0            134  Peoria St & Jackson Blvd     41.877749   \n\n   longitude_end dpcapacity_end  \n0     -87.645980           15.0  \n1     -87.655486           15.0  \n2     -87.648830           15.0  \n3     -87.627750           11.0  \n4     -87.649633           19.0  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>year</th>\n      <th>month</th>\n      <th>week</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>usertype</th>\n      <th>gender</th>\n      <th>starttime</th>\n      <th>stoptime</th>\n      <th>...</th>\n      <th>from_station_id</th>\n      <th>from_station_name</th>\n      <th>latitude_start</th>\n      <th>longitude_start</th>\n      <th>dpcapacity_start</th>\n      <th>to_station_id</th>\n      <th>to_station_name</th>\n      <th>latitude_end</th>\n      <th>longitude_end</th>\n      <th>dpcapacity_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2355134</td>\n      <td>2014</td>\n      <td>6</td>\n      <td>27</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Subscriber</td>\n      <td>Male</td>\n      <td>2014-06-30 23:57:00</td>\n      <td>2014-07-01 00:07:00</td>\n      <td>...</td>\n      <td>131</td>\n      <td>Lincoln Ave &amp; Belmont Ave</td>\n      <td>41.939365</td>\n      <td>-87.668385</td>\n      <td>15.0</td>\n      <td>303</td>\n      <td>Broadway &amp; Cornelia Ave</td>\n      <td>41.945512</td>\n      <td>-87.645980</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2355133</td>\n      <td>2014</td>\n      <td>6</td>\n      <td>27</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Subscriber</td>\n      <td>Male</td>\n      <td>2014-06-30 23:56:00</td>\n      <td>2014-07-01 00:00:00</td>\n      <td>...</td>\n      <td>282</td>\n      <td>Halsted St &amp; Maxwell St</td>\n      <td>41.864580</td>\n      <td>-87.646930</td>\n      <td>15.0</td>\n      <td>22</td>\n      <td>May St &amp; Taylor St</td>\n      <td>41.869482</td>\n      <td>-87.655486</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2355130</td>\n      <td>2014</td>\n      <td>6</td>\n      <td>27</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Subscriber</td>\n      <td>Male</td>\n      <td>2014-06-30 23:33:00</td>\n      <td>2014-06-30 23:35:00</td>\n      <td>...</td>\n      <td>327</td>\n      <td>Sheffield Ave &amp; Webster Ave</td>\n      <td>41.921687</td>\n      <td>-87.653714</td>\n      <td>19.0</td>\n      <td>225</td>\n      <td>Halsted St &amp; Dickens Ave</td>\n      <td>41.919936</td>\n      <td>-87.648830</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2355129</td>\n      <td>2014</td>\n      <td>6</td>\n      <td>27</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Subscriber</td>\n      <td>Female</td>\n      <td>2014-06-30 23:26:00</td>\n      <td>2014-07-01 00:24:00</td>\n      <td>...</td>\n      <td>134</td>\n      <td>Peoria St &amp; Jackson Blvd</td>\n      <td>41.877749</td>\n      <td>-87.649633</td>\n      <td>19.0</td>\n      <td>194</td>\n      <td>State St &amp; Wacker Dr</td>\n      <td>41.887155</td>\n      <td>-87.627750</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2355128</td>\n      <td>2014</td>\n      <td>6</td>\n      <td>27</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Subscriber</td>\n      <td>Female</td>\n      <td>2014-06-30 23:16:00</td>\n      <td>2014-06-30 23:26:00</td>\n      <td>...</td>\n      <td>320</td>\n      <td>Loomis St &amp; Lexington St</td>\n      <td>41.872187</td>\n      <td>-87.661501</td>\n      <td>15.0</td>\n      <td>134</td>\n      <td>Peoria St &amp; Jackson Blvd</td>\n      <td>41.877749</td>\n      <td>-87.649633</td>\n      <td>19.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"ride_sharing.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:03:59.395255Z","iopub.execute_input":"2024-12-30T15:03:59.395555Z","iopub.status.idle":"2024-12-30T15:03:59.400496Z","shell.execute_reply.started":"2024-12-30T15:03:59.395531Z","shell.execute_reply":"2024-12-30T15:03:59.399812Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['trip_id', 'year', 'month', 'week', 'day', 'hour', 'usertype', 'gender',\n       'starttime', 'stoptime', 'tripduration', 'temperature', 'events',\n       'from_station_id', 'from_station_name', 'latitude_start',\n       'longitude_start', 'dpcapacity_start', 'to_station_id',\n       'to_station_name', 'latitude_end', 'longitude_end', 'dpcapacity_end'],\n      dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ride_sharing['usertype']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:08:49.459452Z","iopub.execute_input":"2024-12-30T15:08:49.459791Z","iopub.status.idle":"2024-12-30T15:08:49.466464Z","shell.execute_reply.started":"2024-12-30T15:08:49.459761Z","shell.execute_reply":"2024-12-30T15:08:49.465793Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0          Subscriber\n1          Subscriber\n2          Subscriber\n3          Subscriber\n4          Subscriber\n              ...    \n9495230    Subscriber\n9495231    Subscriber\n9495232    Subscriber\n9495233    Subscriber\n9495234    Subscriber\nName: usertype, Length: 9495235, dtype: object"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Print the information of ride_sharing\nprint(ride_sharing.info())\n\n# Print summary statistics of user_type column\nprint(ride_sharing['usertype'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:04:11.495784Z","iopub.execute_input":"2024-12-30T15:04:11.496165Z","iopub.status.idle":"2024-12-30T15:04:12.468424Z","shell.execute_reply.started":"2024-12-30T15:04:11.496133Z","shell.execute_reply":"2024-12-30T15:04:12.467512Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9495235 entries, 0 to 9495234\nData columns (total 23 columns):\n #   Column             Dtype  \n---  ------             -----  \n 0   trip_id            int64  \n 1   year               int64  \n 2   month              int64  \n 3   week               int64  \n 4   day                int64  \n 5   hour               int64  \n 6   usertype           object \n 7   gender             object \n 8   starttime          object \n 9   stoptime           object \n 10  tripduration       float64\n 11  temperature        float64\n 12  events             object \n 13  from_station_id    int64  \n 14  from_station_name  object \n 15  latitude_start     float64\n 16  longitude_start    float64\n 17  dpcapacity_start   float64\n 18  to_station_id      int64  \n 19  to_station_name    object \n 20  latitude_end       float64\n 21  longitude_end      float64\n 22  dpcapacity_end     float64\ndtypes: float64(8), int64(8), object(7)\nmemory usage: 1.6+ GB\nNone\ncount        9495235\nunique             3\ntop       Subscriber\nfreq         9493780\nName: usertype, dtype: object\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Print the information of ride_sharing\nprint(ride_sharing.info())\n\n# Print summary statistics of user_type column\nprint(ride_sharing['usertype'].describe())\n\n# Convert user_type from integer to category\nride_sharing['user_type_cat'] = ride_sharing['usertype'].astype('category')\n\n# Write an assert statement confirming the change\nassert ride_sharing['user_type_cat'].dtype == 'category'\n\n# Print new summary statistics \nprint(ride_sharing['user_type_cat'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:04:37.061849Z","iopub.execute_input":"2024-12-30T15:04:37.062177Z","iopub.status.idle":"2024-12-30T15:04:38.457608Z","shell.execute_reply.started":"2024-12-30T15:04:37.062149Z","shell.execute_reply":"2024-12-30T15:04:38.456897Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9495235 entries, 0 to 9495234\nData columns (total 23 columns):\n #   Column             Dtype  \n---  ------             -----  \n 0   trip_id            int64  \n 1   year               int64  \n 2   month              int64  \n 3   week               int64  \n 4   day                int64  \n 5   hour               int64  \n 6   usertype           object \n 7   gender             object \n 8   starttime          object \n 9   stoptime           object \n 10  tripduration       float64\n 11  temperature        float64\n 12  events             object \n 13  from_station_id    int64  \n 14  from_station_name  object \n 15  latitude_start     float64\n 16  longitude_start    float64\n 17  dpcapacity_start   float64\n 18  to_station_id      int64  \n 19  to_station_name    object \n 20  latitude_end       float64\n 21  longitude_end      float64\n 22  dpcapacity_end     float64\ndtypes: float64(8), int64(8), object(7)\nmemory usage: 1.6+ GB\nNone\ncount        9495235\nunique             3\ntop       Subscriber\nfreq         9493780\nName: usertype, dtype: object\ncount        9495235\nunique             3\ntop       Subscriber\nfreq         9493780\nName: user_type_cat, dtype: object\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Summing strings and concatenating numbers\n\nIn the previous exercise, you were able to identify that category is the correct data type for user_type and convert it in order to extract relevant statistical summaries that shed light on the distribution of user_type.\n\nAnother common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs.\n\nIn this exercise, you'll be converting the string column duration to the type int. Before that however, you will need to make sure to strip \"minutes\" from the column in order to make sure pandas reads it as numerical. The pandas package has been imported as pd.\n\n\n\n* Use the .strip() method to strip duration of \"minutes\" and store it in the duration_trim column.\n* Convert duration_trim to int and store it in the duration_time column.\n* Write an assert statement that checks if duration_time's data type is now an int.Print the average ride duration.\n","metadata":{}},{"cell_type":"code","source":"ride_sharing['tripduration']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:08:33.432206Z","iopub.execute_input":"2024-12-30T15:08:33.432518Z","iopub.status.idle":"2024-12-30T15:08:33.439174Z","shell.execute_reply.started":"2024-12-30T15:08:33.432494Z","shell.execute_reply":"2024-12-30T15:08:33.438459Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0          10.066667\n1           4.383333\n2           2.100000\n3          58.016667\n4          10.633333\n             ...    \n9495230    11.066667\n9495231    11.033333\n9495232    13.950000\n9495233     6.016667\n9495234    12.350000\nName: tripduration, Length: 9495235, dtype: float64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# # Strip duration of minutes\n# ride_sharing['duration_trim'] = ride_sharing['tripduration'].str.strip('minutes')\n\n# # Convert duration to integer\n# ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype(int)\n# # Write an assert statement making sure of conversion\n# assert ride_sharing['duration_time'].dtype == 'int'\n\n# # Print formed columns and calculate average ride duration \n# print(ride_sharing[['duration','duration_trim','duration_time']])\n# print(ride_sharing['duration_time'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:10:41.222819Z","iopub.execute_input":"2024-12-30T15:10:41.223150Z","iopub.status.idle":"2024-12-30T15:10:41.226572Z","shell.execute_reply.started":"2024-12-30T15:10:41.223124Z","shell.execute_reply":"2024-12-30T15:10:41.225838Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Remove the word 'minutes' from tripduration\nride_sharing['duration_trim'] = ride_sharing['tripduration'].astype(str).str.replace(' minutes', '', regex=False)\n\n# Convert duration_trim to integer\nride_sharing['duration_time'] = ride_sharing['duration_trim'].astype(float).astype(int)\n\n# Assert the conversion to integer\nassert ride_sharing['duration_time'].dtype == 'int'\n\n# Print formed columns and calculate average ride duration\nprint(ride_sharing[['tripduration', 'duration_trim', 'duration_time']])\nprint(\"Mean Duration Ride Time :\",ride_sharing['duration_time'].mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:12:46.863947Z","iopub.execute_input":"2024-12-30T15:12:46.864234Z","iopub.status.idle":"2024-12-30T15:12:58.478380Z","shell.execute_reply.started":"2024-12-30T15:12:46.864212Z","shell.execute_reply":"2024-12-30T15:12:58.477593Z"}},"outputs":[{"name":"stdout","text":"         tripduration       duration_trim  duration_time\n0           10.066667  10.066666666666666             10\n1            4.383333   4.383333333333334              4\n2            2.100000                 2.1              2\n3           58.016667  58.016666666666666             58\n4           10.633333  10.633333333333333             10\n...               ...                 ...            ...\n9495230     11.066667  11.066666666666666             11\n9495231     11.033333  11.033333333333331             11\n9495232     13.950000               13.95             13\n9495233      6.016667   6.016666666666667              6\n9495234     12.350000               12.35             12\n\n[9495235 rows x 3 columns]\nMean Duration Ride Time : 10.956872789351712\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Great work! 11 minutes is really not bad for an average ride duration in a city like San-Francisco. In the next lesson, you're going to jump right ahead into sanity checking the range of values in your data.","metadata":{}},{"cell_type":"markdown","source":"# Tire size constraints\n\nIn this lesson, you're going to build on top of the work you've been doing with the ride_sharing DataFrame. You'll be working with the tire_sizes column which contains data on each bike's tire size.\n\nBicycle tire sizes could be either 26″, 27″ or 29″ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27″.\n\nIn this exercise, you will make sure the tire_sizes column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes.\n\n\n* Convert the tire_sizes column from category to 'int'.\n* Use .loc[] to set all values of tire_sizes above 27 to 27.\n* Reconvert back tire_sizes to 'category' from int.\n* Print the description of the tire_sizes.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Convert tire_sizes to integer\nride_sharing['month'] = ride_sharing['month'].astype('int')\n\n# Set all values above 27 to 27mo\nride_sharing.loc[ride_sharing[\"month\"] > 7, \"month\"] = 7\n\n# Reconvert tire_sizes back to categorical\nride_sharing['month'] = ride_sharing['month'].astype('category')\n\n# Print tire size description\nprint(ride_sharing['month'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:47:38.292229Z","iopub.execute_input":"2024-12-30T15:47:38.292519Z","iopub.status.idle":"2024-12-30T15:47:38.475834Z","shell.execute_reply.started":"2024-12-30T15:47:38.292496Z","shell.execute_reply":"2024-12-30T15:47:38.475039Z"}},"outputs":[{"name":"stdout","text":"count     9495235\nunique          6\ntop             6\nfreq      6988344\nName: month, dtype: int64\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Awesome work! You can look at the new maximum by looking at the top row in the description. Notice how essential it was to convert tire_sizes into integer before setting a new maximum.","metadata":{}},{"cell_type":"markdown","source":"### Back to the future\nA new update to the data pipeline feeding into the ride_sharing DataFrame has been updated to register each ride's date. This information is stored in the ride_date column of the type object, which represents strings in pandas.\n\nA bug was discovered which was relaying rides taken today as taken next year. To fix this, you will find all instances of the ride_date column that occur anytime in the future, and set the maximum possible value of this column to today's date. Before doing so, you would need to convert ride_date to a datetime object.\n\nThe datetime package has been imported as dt, alongside all the packages you've been using till now.\n\n\n\n* Convert ride_date to a datetime object using to_datetime(), then convert the datetime object into a date and store it in ride_dt column.\n* Create the variable today, which stores today's date by using the dt.date.today() function.\n* For all instances of ride_dt in the future, set them to today's date.\n* Print the maximum date in the ride_dt column\n.","metadata":{}},{"cell_type":"code","source":"ride_sharing.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T15:52:56.415769Z","iopub.execute_input":"2024-12-30T15:52:56.416089Z","iopub.status.idle":"2024-12-30T15:52:56.421360Z","shell.execute_reply.started":"2024-12-30T15:52:56.416066Z","shell.execute_reply":"2024-12-30T15:52:56.420547Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Index(['trip_id', 'year', 'month', 'week', 'day', 'hour', 'usertype', 'gender',\n       'starttime', 'stoptime', 'tripduration', 'temperature', 'events',\n       'from_station_id', 'from_station_name', 'latitude_start',\n       'longitude_start', 'dpcapacity_start', 'to_station_id',\n       'to_station_name', 'latitude_end', 'longitude_end', 'dpcapacity_end',\n       'user_type_cat', 'duration_time', 'duration_trim'],\n      dtype='object')"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\n\n# Replace invalid 'day' values (e.g., 0) with 1\nride_sharing['day'] = ride_sharing['day'].replace(0, 1)\n\n# Create a new column 'ride_date' by combining 'year', 'month', and 'day'\nride_sharing['ride_date'] = pd.to_datetime(\n    ride_sharing[['year', 'month', 'day']]\n)\n\n# Print the first few rows to verify\nprint(ride_sharing[['year', 'month', 'day', 'ride_date']].tail())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T16:06:29.077531Z","iopub.execute_input":"2024-12-30T16:06:29.077854Z","iopub.status.idle":"2024-12-30T16:06:29.957675Z","shell.execute_reply.started":"2024-12-30T16:06:29.077828Z","shell.execute_reply":"2024-12-30T16:06:29.956917Z"}},"outputs":[{"name":"stdout","text":"         year month  day  ride_date\n9495230  2017     6    6 2017-06-06\n9495231  2017     6    6 2017-06-06\n9495232  2017     6    6 2017-06-06\n9495233  2017     6    6 2017-06-06\n9495234  2017     6    6 2017-06-06\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import datetime as dt\n\n# Convert ride_date to date\nride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date']).dt.date\n# Save today's date\ntoday = dt.date.today()\n\n# Set all in the future to today's date\nride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n\n# Print maximum of ride_dt column\nprint(ride_sharing['ride_dt'].max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T16:07:14.046508Z","iopub.execute_input":"2024-12-30T16:07:14.046856Z","iopub.status.idle":"2024-12-30T16:07:17.077321Z","shell.execute_reply.started":"2024-12-30T16:07:14.046826Z","shell.execute_reply":"2024-12-30T16:07:17.076465Z"}},"outputs":[{"name":"stdout","text":"2017-06-06\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Great job! Imagine counting the number of rides taken today without having cleaned your ranges correctly. You would have wildly underreported your findings!","metadata":{}},{"cell_type":"markdown","source":"# Finding duplicates\n\nA new update to the data pipeline feeding into ride_sharing has added the ride_id column, which represents a unique identifier for each ride.\n\nThe update however coincided with radically shorter average ride duration times and irregular user birth dates set in the future. Most importantly, the number of rides taken has increased by 20% overnight, leading you to think there might be both complete and incomplete duplicates in the ride_sharing DataFrame.\n\nIn this exercise, you will confirm this suspicion by finding those duplicates. A sample of ride_sharing is in your environment, as well as all the packages you've been working with thus far.\n\n\n\n* Find duplicated rows of ride_id in the ride_sharing DataFrame while setting keep to False.\n* Subset ride_sharing on duplicates and sort by ride_id and assign the results to duplicated_rides.\n* Print the ride_id, duration and user_birth_year columns of duplicated_rides in that order.\n","metadata":{}},{"cell_type":"code","source":"# Find duplicates\nduplicates = ride_sharing.duplicated(\"trip_id\", keep = False)\n\n# Sort your duplicated rides\nduplicated_rides = ride_sharing[duplicates].sort_values(by = 'trip_id')\n\n# Print relevant columns of duplicated_rides\nprint(duplicated_rides[['trip_id','duration_time','user_type_cat']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T16:31:54.651608Z","iopub.execute_input":"2024-12-30T16:31:54.651955Z","iopub.status.idle":"2024-12-30T16:31:55.868035Z","shell.execute_reply.started":"2024-12-30T16:31:54.651930Z","shell.execute_reply":"2024-12-30T16:31:55.867223Z"}},"outputs":[{"name":"stdout","text":"          trip_id  duration_time user_type_cat\n5679603  10958572              8    Subscriber\n5679602  10958572              8    Subscriber\n5653373  10999878              8    Subscriber\n5653372  10999878              8    Subscriber\n5649026  11006910              7    Subscriber\n...           ...            ...           ...\n5250864  11693784              6    Subscriber\n5246907  11707860             19    Subscriber\n5246906  11707860             19    Subscriber\n5245997  11710838             19    Subscriber\n5245996  11710838             19    Subscriber\n\n[94 rows x 3 columns]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Notice that trips are duplicated.\n","metadata":{}},{"cell_type":"markdown","source":"### Treating duplicates\nIn the last exercise, you were able to verify that the new update feeding into ride_sharing contains a bug generating both complete and incomplete duplicated rows for some values of the ride_id column, with occasional discrepant values for the user_birth_year and duration columns.\n\nIn this exercise, you will be treating those duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average duration, and the minimum user_birth_year for each set of incomplete duplicate rows.\n\n\n* Drop complete duplicates in ride_sharing and store the results in ride_dup.\n* Create the statistics dictionary which holds minimum aggregation for user_birth_year and mean aggregation for duration.\n* Drop incomplete duplicates by grouping by ride_id and applying the aggregation in statistics.\n* Find duplicates again and run the assert statement to verify de-duplication.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Drop complete duplicates from ride_sharing\nride_dup = ride_sharing.drop_duplicates()\n\n# Create statistics dictionary for aggregation function\nstatistics = {'user_birth_year': 'min', 'duration': 'mean'}\n\n# Group by ride_id and compute new statistics\nride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n\n# Find duplicated values again\nduplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\nduplicated_rides = ride_unique[duplicates == True]\n\n# Assert duplicates are processed\nassert duplicated_rides.shape[0] == 0","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}