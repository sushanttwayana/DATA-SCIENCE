{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":731448,"sourceType":"datasetVersion","datasetId":376751},{"sourceId":4436,"sourceType":"datasetVersion","datasetId":2672}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hyperparameters Tuning\n\n## Tree hyperparameters\nIn the following exercises you'll revisit the Indian Liver Patient dataset which was introduced in a previous chapter.\n\nYour task is to tune the hyperparameters of a classification tree. Given that this dataset is imbalanced, you'll be using the ROC AUC score as a metric instead of accuracy.\n\nWe have instantiated a DecisionTreeClassifier and assigned to dt with sklearn's default hyperparameters. You can inspect the hyperparameters of dt in your console.\n\nWhich of the following is not a hyperparameter of dt?","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Instantiate dt\ndt = DecisionTreeClassifier(max_depth=2, random_state=1)\n\nprint(dt.get_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:03:54.369550Z","iopub.execute_input":"2025-09-24T05:03:54.369826Z","iopub.status.idle":"2025-09-24T05:03:54.375261Z","shell.execute_reply.started":"2025-09-24T05:03:54.369809Z","shell.execute_reply":"2025-09-24T05:03:54.374449Z"}},"outputs":[{"name":"stdout","text":"<bound method BaseEstimator.get_params of DecisionTreeClassifier(max_depth=2, random_state=1)>\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Set the tree's hyperparameter grid\nIn this exercise, you'll manually set the grid of hyperparameters that will be used to tune the classification tree dt and find the optimal classifier in the next exercise.\n\n\n* Define a grid of hyperparameters corresponding to a Python dictionary called params_dt with:\n\nthe key 'max_depth' set to a list of values 2, 3, and 4\n\nthe key 'min_samples_leaf' set to a list of values 0.12, 0.14, 0.16, 0.18","metadata":{}},{"cell_type":"code","source":"# Define params_dt\nparams_dt = {\n    'max_depth': [2, 3, 4],\n    'min_samples_leaf': [0.12, 0.14, 0.16, 0.18],\n    'max_features': [0.2, 0.4, 0.6, 0.8]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:05:59.430914Z","iopub.execute_input":"2025-09-24T05:05:59.431186Z","iopub.status.idle":"2025-09-24T05:05:59.435358Z","shell.execute_reply.started":"2025-09-24T05:05:59.431171Z","shell.execute_reply":"2025-09-24T05:05:59.434340Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Search for the optimal tree\nIn this exercise, you'll perform grid search using 5-fold cross validation to find dt's optimal hyperparameters. Note that because grid search is an exhaustive process, it may take a lot time to train the model. Here you'll only be instantiating the GridSearchCV object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the .fit() method:\n\ngrid_object.fit(X_train, y_train)\nAn untuned classification tree dt as well as the dictionary params_dt that you defined in the previous exercise are available in your workspace.\n\n\n* Import GridSearchCV from sklearn.model_selection.\n\n* Instantiate a GridSearchCV object using 5-fold CV by setting the parameters:\n\nestimator to dt, param_grid to params_dt and\n\nscoring to 'roc_auc'.","metadata":{}},{"cell_type":"code","source":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_dt\ngrid_dt = GridSearchCV(estimator=dt,\n                       param_grid=params_dt,\n                       scoring='roc_auc',\n                       cv=5,\n                       n_jobs=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:16:16.745231Z","iopub.execute_input":"2025-09-24T05:16:16.745591Z","iopub.status.idle":"2025-09-24T05:16:16.750413Z","shell.execute_reply.started":"2025-09-24T05:16:16.745567Z","shell.execute_reply":"2025-09-24T05:16:16.749343Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Evaluate the optimal tree\nIn this exercise, you'll evaluate the test set ROC AUC score of grid_dt's optimal model.\n\nIn order to do so, you will first determine the probability of obtaining the positive label for each test set observation. You can use the methodpredict_proba() of an sklearn classifier to compute a 2D array containing the probabilities of the negative and positive class-labels respectively along columns.\n\nThe dataset is already loaded and processed for you (numerical features are standardized); it is split into 80% train and 20% test. X_test, y_test are available in your workspace. In addition, we have also loaded the trained GridSearchCV object grid_dt that you instantiated in the previous exercise. Note that grid_dt was trained as follows:\n\ngrid_dt.fit(X_train, y_train)\n\n* Import roc_auc_score from sklearn.metrics.\n\n* Extract the .best_estimator_ attribute from grid_dt and assign it to best_model.\n\n* Predict the test set probabilities of obtaining the positive class y_pred_proba.\n\n* Compute the test set ROC AUC score test_roc_auc of best_model.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nliver_dataset = pd.read_csv('/kaggle/input/indian-liver-patient-dataset/Indian Liver Patient Dataset (ILPD).csv')\nliver_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:19:46.956160Z","iopub.execute_input":"2025-09-24T05:19:46.956477Z","iopub.status.idle":"2025-09-24T05:19:46.974452Z","shell.execute_reply.started":"2025-09-24T05:19:46.956460Z","shell.execute_reply":"2025-09-24T05:19:46.973775Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  albumin  \\\n0   65  Female            0.7               0.1           187       16   \n1   62    Male           10.9               5.5           699       64   \n2   62    Male            7.3               4.1           490       60   \n3   58    Male            1.0               0.4           182       14   \n4   72    Male            3.9               2.0           195       27   \n\n   ag_ratio  sgpt  sgot  alkphos  is_patient  \n0        18   6.8   3.3     0.90           1  \n1       100   7.5   3.2     0.74           1  \n2        68   7.0   3.3     0.89           1  \n3        20   6.8   3.4     1.00           1  \n4        59   7.3   2.4     0.40           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>tot_bilirubin</th>\n      <th>direct_bilirubin</th>\n      <th>tot_proteins</th>\n      <th>albumin</th>\n      <th>ag_ratio</th>\n      <th>sgpt</th>\n      <th>sgot</th>\n      <th>alkphos</th>\n      <th>is_patient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65</td>\n      <td>Female</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>187</td>\n      <td>16</td>\n      <td>18</td>\n      <td>6.8</td>\n      <td>3.3</td>\n      <td>0.90</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>10.9</td>\n      <td>5.5</td>\n      <td>699</td>\n      <td>64</td>\n      <td>100</td>\n      <td>7.5</td>\n      <td>3.2</td>\n      <td>0.74</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>7.3</td>\n      <td>4.1</td>\n      <td>490</td>\n      <td>60</td>\n      <td>68</td>\n      <td>7.0</td>\n      <td>3.3</td>\n      <td>0.89</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58</td>\n      <td>Male</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>182</td>\n      <td>14</td>\n      <td>20</td>\n      <td>6.8</td>\n      <td>3.4</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>Male</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>195</td>\n      <td>27</td>\n      <td>59</td>\n      <td>7.3</td>\n      <td>2.4</td>\n      <td>0.40</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\n\n\n\n# Display basic info about the dataset\nprint(\"Dataset shape:\", liver_dataset.shape)\nprint(\"\\nDataset info:\")\nprint(liver_dataset.info())\nprint(\"\\nFirst few rows:\")\nprint(liver_dataset.head())\n\n# Data preprocessing\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(liver_dataset.isnull().sum())\n\n# Handle missing values if any\nliver_dataset = liver_dataset.dropna()\n\n# Convert categorical variables (like gender) to numerical\nliver_dataset['gender'] = liver_dataset['gender'].map({'Female': 0, 'Male': 1})\n\n# Prepare features (X) and target (y)\n# Using all features for prediction\nX = liver_dataset.drop('is_patient', axis=1)  # Assuming 'is_patient' is the target\ny = liver_dataset['is_patient']\n\n# Split the data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# X_train.fillna()\n# X_test.fillna()\n# y_train.fillna()\n# y_test.fillna()\n\n# Display split results\nprint(f\"\\nTraining set shape: {X_train.shape}\")\nprint(f\"Test set shape: {X_test.shape}\")\nprint(f\"Target distribution in training set:\")\nprint(y_train.value_counts(normalize=True))\nprint(f\"Target distribution in test set:\")\nprint(y_test.value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:19:47.304312Z","iopub.execute_input":"2025-09-24T05:19:47.304594Z","iopub.status.idle":"2025-09-24T05:19:47.342286Z","shell.execute_reply.started":"2025-09-24T05:19:47.304580Z","shell.execute_reply":"2025-09-24T05:19:47.341568Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (583, 11)\n\nDataset info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 583 entries, 0 to 582\nData columns (total 11 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   age               583 non-null    int64  \n 1   gender            583 non-null    object \n 2   tot_bilirubin     583 non-null    float64\n 3   direct_bilirubin  583 non-null    float64\n 4   tot_proteins      583 non-null    int64  \n 5   albumin           583 non-null    int64  \n 6   ag_ratio          583 non-null    int64  \n 7   sgpt              583 non-null    float64\n 8   sgot              583 non-null    float64\n 9   alkphos           579 non-null    float64\n 10  is_patient        583 non-null    int64  \ndtypes: float64(5), int64(5), object(1)\nmemory usage: 50.2+ KB\nNone\n\nFirst few rows:\n   age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  albumin  \\\n0   65  Female            0.7               0.1           187       16   \n1   62    Male           10.9               5.5           699       64   \n2   62    Male            7.3               4.1           490       60   \n3   58    Male            1.0               0.4           182       14   \n4   72    Male            3.9               2.0           195       27   \n\n   ag_ratio  sgpt  sgot  alkphos  is_patient  \n0        18   6.8   3.3     0.90           1  \n1       100   7.5   3.2     0.74           1  \n2        68   7.0   3.3     0.89           1  \n3        20   6.8   3.4     1.00           1  \n4        59   7.3   2.4     0.40           1  \n\nMissing values:\nage                 0\ngender              0\ntot_bilirubin       0\ndirect_bilirubin    0\ntot_proteins        0\nalbumin             0\nag_ratio            0\nsgpt                0\nsgot                0\nalkphos             4\nis_patient          0\ndtype: int64\n\nTraining set shape: (405, 10)\nTest set shape: (174, 10)\nTarget distribution in training set:\nis_patient\n1    0.716049\n2    0.283951\nName: proportion, dtype: float64\nTarget distribution in test set:\nis_patient\n1    0.712644\n2    0.287356\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Fit grid_dt to the training data\ngrid_dt.fit(X_train, y_train)\n\n#Extract best  hyperparameters from grid_dt\nbest_hyperparams = grid_dt.best_params_\n\nprint(\"Best hyperparameters:\\n\", best_hyperparams)\n\n# Extract best CV score from 'grid_dt'\nbest_CV_score = grid_dt.best_score_\nprint('BEST CV accuracy'.format(best_CV_score))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:21:05.729162Z","iopub.execute_input":"2025-09-24T05:21:05.729482Z","iopub.status.idle":"2025-09-24T05:21:06.196023Z","shell.execute_reply.started":"2025-09-24T05:21:05.729464Z","shell.execute_reply":"2025-09-24T05:21:06.195176Z"}},"outputs":[{"name":"stdout","text":"Best hyperparameters:\n {'max_depth': 3, 'max_features': 0.6, 'min_samples_leaf': 0.12}\nBEST CV accuracy\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Import roc_auc_score from sklearn.metrics\nfrom sklearn.metrics import roc_auc_score\n\n# Extract the best estimator\nbest_model = grid_dt.best_estimator_\n\n# Predict the test set probabilities of the positive class\ny_pred_proba = best_model.predict_proba(X_test)[:,1]\n\n# Compute test_roc_auc\ntest_roc_auc = roc_auc_score(y_test, y_pred_proba)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:21:39.096674Z","iopub.execute_input":"2025-09-24T05:21:39.096975Z","iopub.status.idle":"2025-09-24T05:21:39.106026Z","shell.execute_reply.started":"2025-09-24T05:21:39.096957Z","shell.execute_reply":"2025-09-24T05:21:39.105231Z"}},"outputs":[{"name":"stdout","text":"Test set ROC AUC score: 0.727\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Random forests hyperparameters\nIn the following exercises, you'll be revisiting the Bike Sharing Demand dataset that was introduced in a previous chapter. Recall that your task is to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. For this purpose, you'll be tuning the hyperparameters of a Random Forests regressor.\n\nWe have instantiated a RandomForestRegressor called rf using sklearn's default hyperparameters. You can inspect the hyperparameters of rf in your console.\n\nWhich of the following is not a hyperparameter of rf?","metadata":{}},{"cell_type":"code","source":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate rf\nrf = RandomForestRegressor(n_estimators=25,\n            random_state=2)\n            \n\nprint(rf.get_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:27:40.351242Z","iopub.execute_input":"2025-09-24T05:27:40.352038Z","iopub.status.idle":"2025-09-24T05:27:40.356727Z","shell.execute_reply.started":"2025-09-24T05:27:40.352017Z","shell.execute_reply":"2025-09-24T05:27:40.356033Z"}},"outputs":[{"name":"stdout","text":"<bound method BaseEstimator.get_params of RandomForestRegressor(n_estimators=25, random_state=2)>\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Set the hyperparameter grid of RF\nIn this exercise, you'll manually set the grid of hyperparameters that will be used to tune rf's hyperparameters and find the optimal regressor. For this purpose, you will be constructing a grid of hyperparameters and tune the number of estimators, the maximum number of features used when splitting each node and the minimum number of samples (or fraction) per leaf.\n\n\n* Define a grid of hyperparameters corresponding to a\n* Python dictionary called params_rf with:\n\nthe key 'n_estimators' set to a list of values 100, 350, 500\n\nthe key 'max_features' set to a list of values 'log2', 'auto', 'sqrt'\n\nthe key 'min_samples_leaf' set to a list of values 2, 10, 30","metadata":{}},{"cell_type":"code","source":"bike_dataset = pd.read_csv('/kaggle/input/london-bike-sharing-dataset/london_merged.csv')\nbike_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:30:48.429114Z","iopub.execute_input":"2025-09-24T05:30:48.429428Z","iopub.status.idle":"2025-09-24T05:30:48.464188Z","shell.execute_reply.started":"2025-09-24T05:30:48.429412Z","shell.execute_reply":"2025-09-24T05:30:48.463409Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"             timestamp  cnt   t1   t2    hum  wind_speed  weather_code  \\\n0  2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0   \n1  2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0   \n2  2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0   \n3  2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0   \n4  2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0   \n\n   is_holiday  is_weekend  season  \n0         0.0         1.0     3.0  \n1         0.0         1.0     3.0  \n2         0.0         1.0     3.0  \n3         0.0         1.0     3.0  \n4         0.0         1.0     3.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>cnt</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>hum</th>\n      <th>wind_speed</th>\n      <th>weather_code</th>\n      <th>is_holiday</th>\n      <th>is_weekend</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-04 00:00:00</td>\n      <td>182</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>93.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-04 01:00:00</td>\n      <td>138</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>93.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-01-04 02:00:00</td>\n      <td>134</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>96.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-01-04 03:00:00</td>\n      <td>72</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-01-04 04:00:00</td>\n      <td>47</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>93.0</td>\n      <td>6.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Load the dataset\nbike_dataset = pd.read_csv('/kaggle/input/london-bike-sharing-dataset/london_merged.csv')\n\n# Prepare the features and target variable\n# Assuming 'cnt' is the target variable (bike count)\nX = bike_dataset.drop(['timestamp', 'cnt'], axis=1)  # Features (excluding timestamp and target)\ny = bike_dataset['cnt']  # Target variable\n\n# Split the dataset into 80% training and 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:30:54.845517Z","iopub.execute_input":"2025-09-24T05:30:54.845784Z","iopub.status.idle":"2025-09-24T05:30:54.875158Z","shell.execute_reply.started":"2025-09-24T05:30:54.845769Z","shell.execute_reply":"2025-09-24T05:30:54.874101Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate rf\nrf = RandomForestRegressor(n_estimators=25,\n            random_state=2)\n            \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:31:03.974169Z","iopub.execute_input":"2025-09-24T05:31:03.974467Z","iopub.status.idle":"2025-09-24T05:31:04.758625Z","shell.execute_reply.started":"2025-09-24T05:31:03.974452Z","shell.execute_reply":"2025-09-24T05:31:04.757476Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(n_estimators=25, random_state=2)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Define the dictionary 'params_rf'\nparams_rf = {\n    'n_estimators':[100,350,500],\n    'max_features': ['log2','auto','sqrt'],\n    'min_samples_leaf': [2, 10, 30]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:31:11.212269Z","iopub.execute_input":"2025-09-24T05:31:11.212607Z","iopub.status.idle":"2025-09-24T05:31:11.217640Z","shell.execute_reply.started":"2025-09-24T05:31:11.212589Z","shell.execute_reply":"2025-09-24T05:31:11.216464Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Search for the optimal forest\nIn this exercise, you'll perform grid search using 3-fold cross validation to find rf's optimal hyperparameters. To evaluate each model in the grid, you'll be using the negative mean squared error metric.\n\nNote that because grid search is an exhaustive search process, it may take a lot time to train the model. Here you'll only be instantiating the GridSearchCV object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the .fit() method:\n\ngrid_object.fit(X_train, y_train)\nThe untuned random forests regressor model rf as well as the dictionary params_rf that you defined in the previous exercise are available in your workspace.\n\n\n* Import GridSearchCV from sklearn.model_selection.\n\n* Instantiate a GridSearchCV object using 3-fold CV by using negative mean squared error as the scoring metric.","metadata":{}},{"cell_type":"code","source":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_rf\ngrid_rf = GridSearchCV(estimator=rf,\n                       param_grid=params_rf,\n                       scoring='neg_mean_squared_error',\n                       cv=3,\n                       verbose=1,\n                       n_jobs=-1)\n\n                       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:33:00.402659Z","iopub.execute_input":"2025-09-24T05:33:00.402958Z","iopub.status.idle":"2025-09-24T05:33:00.408055Z","shell.execute_reply.started":"2025-09-24T05:33:00.402940Z","shell.execute_reply":"2025-09-24T05:33:00.406952Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Fit grid_rf to the training set    \ngrid_rf.fit(X_train, y_train) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:33:43.236735Z","iopub.execute_input":"2025-09-24T05:33:43.236997Z","iopub.status.idle":"2025-09-24T05:35:00.841187Z","shell.execute_reply.started":"2025-09-24T05:33:43.236983Z","shell.execute_reply":"2025-09-24T05:35:00.839875Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 27 candidates, totalling 81 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=3,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n                         'min_samples_leaf': [2, 10, 30],\n                         'n_estimators': [100, 350, 500]},\n             scoring='neg_mean_squared_error', verbose=1)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Extract best hyperparameters from grid_rf\n\nbest_hyperparams = grid_rf.best_params_\n\nprint('Best hyperparams:\\n', best_hyperparams)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:36:06.804866Z","iopub.execute_input":"2025-09-24T05:36:06.805137Z","iopub.status.idle":"2025-09-24T05:36:06.809558Z","shell.execute_reply.started":"2025-09-24T05:36:06.805122Z","shell.execute_reply":"2025-09-24T05:36:06.808673Z"}},"outputs":[{"name":"stdout","text":"Best hyperparams:\n {'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Evaluate the optimal forest\nIn this last exercise of the course, you'll evaluate the test set RMSE of grid_rf's optimal model.\n\nThe dataset is already loaded and processed for you and is split into 80% train and 20% test. In your environment are available X_test, y_test and the function mean_squared_error from sklearn.metrics under the alias MSE. In addition, we have also loaded the trained GridSearchCV object grid_rf that you instantiated in the previous exercise. Note that grid_rf was trained as follows:\n\ngrid_rf.fit(X_train, y_train)\n\n* Import mean_squared_error as MSE from sklearn.metrics.\n\n* Extract the best estimator from grid_rf and assign it to best_model.\n\n* Predict best_model's test set labels and assign the result to y_pred.\n\n* Compute best_model's test set RMSE.\n\n\n","metadata":{}},{"cell_type":"code","source":"# Import mean_squared_error from sklearn.metrics as MSE \nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Extract the best estimator\nbest_model = grid_rf.best_estimator_\n\n# Predict test set labels\ny_pred = best_model.predict(X_test)\n\n# Compute rmse_test\nrmse_test = MSE(y_test, y_pred) ** (1/2)\n\n# Print rmse_test\nprint('Test RMSE of best model: {:.3f}'.format(rmse_test)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T05:36:39.652657Z","iopub.execute_input":"2025-09-24T05:36:39.652914Z","iopub.status.idle":"2025-09-24T05:36:39.968815Z","shell.execute_reply.started":"2025-09-24T05:36:39.652900Z","shell.execute_reply":"2025-09-24T05:36:39.968027Z"}},"outputs":[{"name":"stdout","text":"Test RMSE of best model: 904.129\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}